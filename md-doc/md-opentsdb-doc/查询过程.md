---
typora-copy-images-to: opentsdb-source-analysis-image
---

# 1. 编译安装

本章介绍OpenTsdb的源码编译和安装方式。

## 1.1 源码下载

进入网站https://github.com/OpenTSDB/opentsdb，切换到如下版本，点击Download Zip，下载源码包

![1534261097431](opentsdb-source-analysis-image\1534261097431.png)       ![1534260859328](opentsdb-source-analysis-image\1534260859328.png)                                                           

​              图1.1  版本选择                                                               图1.2 下载ZIP包

将下载的源码解压到指定目录，比如/data1/zhangwusheng/ctyun/opentsdb-2.4.0RC2，以后均以$OPENTSDB_HOME代指此目录。

解压后的目录结构如下图所示：

![1534261585406](opentsdb-source-analysis-image\1534261585406.png)

设置环境变量如下：

export OPENTSDB_HOME=/data1/zhangwusheng/ctyun/opentsdb-2.4.0RC2

## 1.2 源码编译

OpenTsdb采用了Makefile编译安装的形式。

cd $ OPENTSDB_HOME

./build.sh



## 1.3 Opentsdb使用简介

# AsyncHBASE使用

# 程序启动过程：



# 查询对象



Request parameters include:

| QueryString        | Data Type       | Required | Default        | Example     |
| ------------------ | --------------- | -------- | -------------- | ----------- |
| start              | String, Integer | Required |                | 1h-ago      |
| end                | String, Integer | Optional | *current time* | 1s-ago      |
| m or tsuids        | Array           | Required |                | *See below* |
| no_annotations     | Boolean         | Optional | false          | false       |
| global_annotations | Boolean         | Optional | false          | true        |
| ms                 | Boolean         | Optional | false          | true        |
| show_tsuids        | Boolean         | Optional | false          | true        |
| show_summary       | Boolean         | Optional | false          | true        |
| show_stats         | Boolean         | Optional | false          | true        |
| show_query         | Boolean         | Optional | false          | true        |
|                    | Boolean         | Optional | false          | true        |
| timezone           | String          | Optional | UTC            | Asia/Kabul  |
|                    | Boolean         | Optional | false          | true        |



Request parameters include:

Request parameters include:

| QueryString        | Description                                                  | Example     |
| ------------------ | ------------------------------------------------------------ | ----------- |
| start              | The start time for the query. This can be a relative or absolute timestamp. See [Querying or Reading Data](http://opentsdb.net/docs/build/html/user_guide/query/index.html) for details. | 1h-ago      |
| end                | An end time for the query. If not supplied, the TSD will assume the local system time on the server. This may be a relative or absolute timestamp. See [Querying or Reading Data](http://opentsdb.net/docs/build/html/user_guide/query/index.html) for details. | 1s-ago      |
| m or tsuids        | One or more sub queries used to select the time series to return. These may be metric `m` or TSUID `tsuids` queries | *See below* |
| no_annotations     | Whether or not to return annotations with a query. The default is to return annotations for the requested timespan but this flag can disable the return. This affects both local and global notes and overrides `globalAnnotations` | false       |
| global_annotations | Whether or not the query should retrieve global annotations for the requested timespan | true        |
| ms                 | Whether or not to output data point timestamps in milliseconds or seconds. The msResolution flag is recommended. If this flag is not provided and there are multiple data points within a second, those data points will be down sampled using the query's aggregation function. | true        |
| show_tsuids        | Whether or not to output the TSUIDs associated with timeseries in the results. If multiple time series were aggregated into one set, multiple TSUIDs will be returned in a sorted manner | true        |
| show_summary       | Whether or not to show a summary of timings surrounding the query in the results. This creates another object in the map that is unlike the data point objects. See [Query Details and Stats](http://opentsdb.net/docs/build/html/user_guide/query/stats.html) | true        |
| show_stats         | Whether or not to show detailed timings surrounding the query in the results. This creates another object in the map that is unlike the data point objects. See [Query Details and Stats](http://opentsdb.net/docs/build/html/user_guide/query/stats.html) | true        |
| show_query         | Whether or not to return the original sub query with the query results. If the request contains many sub queries then this is a good way to determine which results belong to which sub query. Note that in the case of a `*` or wildcard query, this can produce a lot of duplicate output. | true        |
|                    | Can be passed to the JSON with a POST to delete any data points that match the given query. | true        |
| timezone           | An optional timezone for calendar-based downsampling. Must be a valid [timezone](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) database name supported by the JRE installed on the TSD server. | Asia/Kabul  |
|                    | Whether or not use the calendar based on the given timezone for downsampling intervals | true        |



## Sub Queries

An OpenTSDB query requires at least one sub query, a means of selecting which time series should be included in the result set. There are two types:

- **Metric Query** - The full name of a metric is supplied along with an optional list of tags. This is optimized for aggregating multiple time series into one result.
- **TSUID Query** - A list of one or more TSUIDs that share a common metric. This is optimized for fetching individual time series where aggregation is not required.

A query can include more than one sub query and any mixture of the two types. When submitting a query via content body, if a list of TSUIDs is supplied, the metric and tags for that particular sub query will be ignored.



Each sub query can retrieve individual or groups of timeseries data, performing aggregation or grouping calculations on each set. Fields for each sub query include:



| Name                 | Data Type | Required | Description                                                  | Default     | Example            |
| -------------------- | --------- | -------- | ------------------------------------------------------------ | ----------- | ------------------ |
| aggregator           | String    | Required | The name of an aggregation function to use. See [/api/aggregators](http://opentsdb.net/docs/build/html/api_http/aggregators.html) |             | sum                |
| metric               | String    | Required | The name of a metric stored in the system                    |             | sys.cpu.0          |
| rate                 | Boolean   | Optional | Whether or not the data should be converted into deltas before returning. This is useful if the metric is a continuously incrementing counter and you want to view the rate of change between data points. | false       | true               |
| rateOptions          | Map       | Optional | Monotonically increasing counter handling options            | *See below* | *See below*        |
| downsample           | String    | Optional | An optional downsampling function to reduce the amount of data returned. | *See below* | 5m-avg             |
| tags                 | Map       | Optional | To drill down to specific timeseries or group results by tag, supply one or more map values in the same format as the query string. Tags are converted to filters in 2.2. See the notes below about conversions. Note that if no tags are specified, all metrics in the system will be aggregated into the results. *Deprecated in 2.2* |             | *See Below*        |
| filters *(2.2)*      | List      | Optional | Filters the time series emitted in the results. Note that if no filters are specified, all time series for the given metric will be aggregated into the results. |             | *See Below*        |
| explicitTags *(2.3)* | Boolean   | Optional | Returns the series that include only the tag keys provided in the filters. | false       | true               |
| percentiles *(2.4)*  | List      | Optional | Fetches histogram data for the metric and computes the given list of percentiles on the data. Percentiles are floating point values from 0 to 100. More details below. |             | [99.9, 95.0, 75.0] |



示例查询：

[http://10.251.44.120:8153/api/query?start=2015/01/01-00:00:00&end=2016/01/01-00:00:00&m=sum:temperature{city=*,zip_code=*,latitude=*}{city=not_literal_or(shanghai)}&m=sum:wind{city=*,zip_code=*,latitude=*}{city=not_literal_or(shanghai)}&show_query&show_stats&show_summary](http://10.251.44.120:8153/api/query?start=2015/01/01-00:00:00&end=2016/01/01-00:00:00&m=sum:temperature%7bcity=*,zip_code=*,latitude=*%7d%7bcity=not_literal_or(shanghai)%7d&show_query&show_stats&show_summary) 



其中上面整个URL串对应一个HttpQuery，

query后面的内容解析为一个，

其中的m参数解析为一个TSSubQuery对象，因为有两个m参数，实际上对应的是两个TSSubQuery，因此这两个TSSubQuery对象又封装为一个TSQuery对象，参数start，end，show_query&show_stats&show_summary等均是TSQuery的成员变量。

从上面的文档中可以看出，一次查询必须包含至少一个子查询，可以是m子查询，也可以是tsuid子查询，也可以是两种查询混合在一起。

> OpenTSDB query requires at least one sub query



## QueryStats

各种统计指标


## HttpQuery

主要是HTTP请求的处理，方法列表如下，不再详述：

![1534314178401](opentsdb-source-analysis-image\1534314178401.png)![1534314205921](opentsdb-source-analysis-image\1534314205921.png)



这里有一个函数需要注意一下，可以进行HTTP Method的转换：

如果url里面带了method_override参数，那么可以理解为把get方法转换为对应的HTTP方法，比如如果参数里面method_override=post，那么对应opentsdb来讲，就认为这个请求是个POST请求额，而不是get请求

```
public HttpMethod getAPIMethod() {
  if (this.method() != HttpMethod.GET) {
    return this.method();
  } else {
    if (this.hasQueryStringParam("method_override")) {
      final String qs_method = this.getQueryStringParam("method_override");
      if (qs_method == null || qs_method.isEmpty()) {
        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED,
            "Missing method override value");
      }
      if (qs_method.toLowerCase().equals("get")) {
        // you can't fix dumb
        return HttpMethod.GET;
      } else if (qs_method.toLowerCase().equals("post")){
        return HttpMethod.POST;
      } else if (qs_method.toLowerCase().equals("put")){
        return HttpMethod.PUT;
      } else if (qs_method.toLowerCase().equals("delete")){
        return HttpMethod.DELETE;
      } else {
        throw new BadRequestException(HttpResponseStatus.METHOD_NOT_ALLOWED,
          "Unknown or unsupported method override value");
      }
    }

    // no override, so just return the method
    return this.method();
  }
}
```

返回结果这个函数可以稍微注意一下，无论成功还是失败，都是通过SendSuccess来标记一下，做一些统计：

```
  private class SendSuccess implements ChannelFutureListener {
    @Override
    public void operationComplete(final ChannelFuture future) throws Exception {
      if(future.isSuccess()) {
        stats.markSent();}
      else
        stats.markSendFailed();
    }
  }

public void sendBuffer(final HttpResponseStatus status,
                        final ChannelBuffer buf,
                        final String contentType) {
  if (!chan.isConnected()) {
    if(stats != null) {
      stats.markSendFailed();
    }
    done();
    return;
  }
  response.headers().set(HttpHeaders.Names.CONTENT_TYPE, contentType);

  // TODO(tsuna): Server, X-Backend, etc. headers.
  // only reset the status if we have the default status, otherwise the user
  // already set it
  response.setStatus(status);
  response.setContent(buf);
  final boolean keepalive = HttpHeaders.isKeepAlive(request);
  if (keepalive) {
    HttpHeaders.setContentLength(response, buf.readableBytes());
  }
  final ChannelFuture future = chan.write(response);
  if (stats != null) {
    future.addListener(new SendSuccess());
  }
  if (!keepalive) {
    future.addListener(ChannelFutureListener.CLOSE);
  }
  done();
}
```



程序入口类：

## OpenTSDBMain

主要提供了几个工具的统一入口

# 查询过程

1.入口函数



net.opentsdb.tsd.QueryRpc

```java
private void handleQuery(final TSDB tsdb, final HttpQuery query, 
    final boolean allow_expressions) {
         
```
allow_expressions参数只有在/api/query/gexp这个endpoint中才会是true，在普通查询中是false。



首先把HttpQuery对象转换为TSQuery对象，HttpQuery对象是请求参数，TSQuery对象理解为解析后的参数对象
```
public static TSQuery parseQuery(final TSDB tsdb, final HttpQuery query,
    final List<ExpressionTree> expressions) {
  final TSQuery data_query = new TSQuery();
  
  data_query.setStart(query.getRequiredQueryStringParam("start"));
  data_query.setEnd(query.getQueryStringParam("end"));
  
  if (query.hasQueryStringParam("padding")) {
    data_query.setPadding(true);
  }
  
  if (query.hasQueryStringParam("no_annotations")) {
    data_query.setNoAnnotations(true);
  }
  
  if (query.hasQueryStringParam("global_annotations")) {
    data_query.setGlobalAnnotations(true);
  }
  
  if (query.hasQueryStringParam("show_tsuids")) {
    data_query.setShowTSUIDs(true);
  }
  
  if (query.hasQueryStringParam("ms")) {
    data_query.setMsResolution(true);
  }
  
  if (query.hasQueryStringParam("show_query")) {
    data_query.setShowQuery(true);
  }  
  
  if (query.hasQueryStringParam("show_stats")) {
    data_query.setShowStats(true);
  }    
  
  if (query.hasQueryStringParam("show_summary")) {
      data_query.setShowSummary(true);
  }
  
  // handle tsuid queries first
  if (query.hasQueryStringParam("tsuid")) {
    final List<String> tsuids = query.getQueryStringParams("tsuid");     
    for (String q : tsuids) {
      parseTsuidTypeSubQuery(q, data_query);
    }
  }
  
  if (query.hasQueryStringParam("m")) {
    final List<String> legacy_queries = query.getQueryStringParams("m");      
    for (String q : legacy_queries) {
      parseMTypeSubQuery(q, data_query);
    }
  }
  
  // TODO - testing out the graphite style expressions here with the "exp" 
  // param that could stand for experimental or expression ;)
  //传过来的只有在/api/query/gexp或者/api/query才不会为空。
  if (expressions != null) {
    if (query.hasQueryStringParam("exp")) {
      final List<String> uri_expressions = query.getQueryStringParams("exp");
      final List<String> metric_queries = new ArrayList<String>(
          uri_expressions.size());
      // parse the expressions into their trees. If one or more expressions 
      // are improper then it will toss an exception up
      expressions.addAll(Expressions.parseExpressions(
          uri_expressions, data_query, metric_queries));
      // iterate over each of the parsed metric queries and store it in the
      // TSQuery list so that we fetch the data for them.
      for (final String mq: metric_queries) {
        parseMTypeSubQuery(mq, data_query);
      }
    }
  } else {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Received a request with an expression but at the "
          + "wrong endpoint: " + query);
    }
  }
  
  if (data_query.getQueries() == null || data_query.getQueries().size() < 1) {
    throw new BadRequestException("Missing sub queries");
  }

  // Filter out duplicate queries
  Set<TSSubQuery> query_set = new LinkedHashSet<TSSubQuery>(data_query.getQueries());
  data_query.getQueries().clear();
  data_query.getQueries().addAll(query_set);

  return data_query;
}
```


这个函数主要完成一个逻辑，解析Tsid或者m参数的查询，主要是下面两行函数：



```

// handle tsuid queries first
  if (query.hasQueryStringParam("tsuid")) {
    final List<String> tsuids = query.getQueryStringParams("tsuid");     
    for (String q : tsuids) {
      parseTsuidTypeSubQuery(q, data_query);
    }
  }

  if (query.hasQueryStringParam("m")) {
    final List<String> legacy_queries = query.getQueryStringParams("m");      
    for (String q : legacy_queries) {
      parseMTypeSubQuery(q, data_query);
    }
  }

```


# 压缩后的列格式

net.opentsdb.core.CompactionQueue.Compaction#buildHeapProcessAnnotations

从下面可以看出，qualifier长度不为2，有可能是Annotation或者


```flow
st=>start: Start
e=>end: End
op1=>operation: len=qualifier.length
cond_qual_is_dp=>condition: len %2 == 0?
cond_qual_is_annoation=>condition: qual[0]==0x01?
cond_qual_is_hist=>condition: qual[0]==0x6?
cond_qual_is_append=>condition: qual[0]==0x5?
sub_decode_annoation=>subroutine: JSON.parseToObject
(kv.value(), Annotation.class)
sub_decode_hist=>subroutine: Internal.decodeHistogramDataPoint
(tsdb, kv);
sub_decode_append=>subroutine: AppendDataPoints.parseKeyValue
sub_decode_dps=>subroutine: ColumnDatapointIterator
sub_warn=>subroutine: Log.Warn & Continue

st->op1->cond_qual_is_dp
cond_qual_is_dp(no)->cond_qual_is_annoation
cond_qual_is_dp(yes,right)->sub_decode_dps->e
cond_qual_is_annoation(no)->cond_qual_is_hist
cond_qual_is_annoation(yes, right)->sub_decode_annoation->e
cond_qual_is_hist(no)->cond_qual_is_append
cond_qual_is_hist(yes, right)->sub_decode_hist->e
cond_qual_is_append(no)->sub_warn->e
cond_qual_is_append(yes, right)->sub_decode_append->e
```


```
for (final KeyValue kv : row) {
  byte[] qual = kv.qualifier();
  int len = qual.length;
  //这里就是%2的意思
  if ((len & 1) != 0) {
    // process annotations and other extended formats
    //qual[0]=0x01表示是Annotation
    if (qual[0] == Annotation.PREFIX()) {
      //如果是Annotation，增加到annotations数组
      annotations.add(JSON.parseToObject(kv.value(), Annotation.class));
    } else if (qual[0] == HistogramDataPoint.PREFIX) {
      //qual[0] =0x6表示HistogramDataPoint
      try {
        HistogramDataPoint histogram = 
            Internal.decodeHistogramDataPoint(tsdb, kv);
        histograms.add(histogram);
      } catch (Throwable t) {
        LOG.error("Failed to decode histogram data point", t);
      }
    } else if (qual[0] == AppendDataPoints.APPEND_COLUMN_PREFIX){
      compactedKVTimestamp = Math.max(compactedKVTimestamp, kv.timestamp());
      final AppendDataPoints adp = new AppendDataPoints();
      tot_values += adp.parseKeyValue(tsdb, kv).size();
      last_append_column = new KeyValue(kv.key(), kv.family(),
          adp.qualifier(), kv.timestamp(), adp.value());
      if (longest == null ||
          longest.qualifier().length < last_append_column.qualifier().length) {
        longest = last_append_column;
      }
      final ColumnDatapointIterator col =
          new ColumnDatapointIterator(last_append_column);
      if (col.hasMoreData()) {
        heap.add(col);
      }
    } else {
      LOG.warn("Ignoring unexpected extended format type " + qual[0]);
    }
    continue;
  }
  // estimate number of points based on the size of the first entry
  // in the column; if ms/sec datapoints are mixed, this will be
  // incorrect, which will cost a reallocation/copy
  final int entry_size = Internal.inMilliseconds(qual) ? 4 : 2;
  tot_values += (len + entry_size - 1) / entry_size;
  if (longest == null || longest.qualifier().length < kv.qualifier().length) {
    longest = kv;
  }
  ColumnDatapointIterator col = new ColumnDatapointIterator(kv);
  compactedKVTimestamp = Math.max(compactedKVTimestamp, kv.timestamp());
  if (col.hasMoreData()) {
    heap.add(col);
  }
  to_delete.add(kv);
}
```



Append模式的Qualifier获取：
net.opentsdb.core.Internal#extractQualifier

Qualifier是存放在value中的，所以调用首先parseKeyValue,但是传入的是KeyValue的Value。

Append模式的是把标记、qualifer和数据长度一起放到了两个（秒）或者四个字节（毫秒）里面。

net.opentsdb.core.Internal#extractQualifier
```
public static byte[] extractQualifier(final byte[] qualifier, 
    final int offset) {
  validateQualifier(qualifier, offset);
  if ((qualifier[offset] & Const.MS_BYTE_FLAG) == Const.MS_BYTE_FLAG) {
    return new byte[] { qualifier[offset], qualifier[offset + 1],
        qualifier[offset + 2], qualifier[offset + 3] };
  } else {
    return new byte[] { qualifier[offset], qualifier[offset + 1] };
  }
}
```

net.opentsdb.core.Internal#getValueLengthFromQualifier(byte[], int)

qualifer最后三个bit表示长度

```
public static byte getValueLengthFromQualifier(final byte[] qualifier, 
    final int offset) {
  validateQualifier(qualifier, offset);    
  short length;
  if ((qualifier[offset] & Const.MS_BYTE_FLAG) == Const.MS_BYTE_FLAG) {
    length = (short) (qualifier[offset + 3] & Internal.LENGTH_MASK); 
  } else {
    length = (short) (qualifier[offset + 1] & Internal.LENGTH_MASK);
  }
  return (byte) (length + 1);
}
```

时间戳是这么表示的：如果是毫秒，取出四字节，然后22位

```
public static int getOffsetFromQualifier(final byte[] qualifier, 
    final int offset) {
  validateQualifier(qualifier, offset);
  if ((qualifier[offset] & Const.MS_BYTE_FLAG) == Const.MS_BYTE_FLAG) {
    return (int)(Bytes.getUnsignedInt(qualifier, offset) & 0x0FFFFFC0) 
      >>> Const.MS_FLAG_BITS;
  } else {
    final int seconds = (Bytes.getUnsignedShort(qualifier, offset) & 0xFFFF) 
      >>> Const.FLAG_BITS;
    return seconds * 1000;
  }
}
```



### 秒类型

当OpenTSDB接收到一个新的DataPoint的时候，如果请求中的时间戳是秒，那么就会插入一个如下模型的数据。

判断请求中的时间戳为秒或毫秒的方法是基于时间戳数值的大小，如果时间戳的值的超过无符号整数的最大值（即4个字节的长度），那么该时间戳是毫秒，否则为秒。

![Qualifier-Second](C:/Work/Source/docs/md-doc/md-opentsdb-doc/Qualifier-Second.png)

- Value长度：Value的实际长度是Qualifier的最后3个bit的值加1，即(qualifier & 0x07) + 1。表示该时间戳对应的值的字节数。所以，值的字节数的范围是1到8个字节。
- Value类型：Value的类型由Qualifier的倒数第4个bit表示，即(qualifier & 0x08)。如果值为1，表示Value的类型为float；如果值为0，表示Value的类型为long。
- 时间戳：时间戳的值由Qualifier的第1到第12个bit表示，即(qualifier & 0xFFF0) >>>4。由于秒级的时间戳最大值不会大于3600，所以qualifer的第1个bit肯定不会是1。



### 毫秒类型

当OpenTSDB接收到一个新的DataPoint的时候，如果请求中的时间戳是毫秒，那么就会插入一个如下模型的数据。

![Qualifier-milisecond](C:/Work/Source/docs/md-doc/md-opentsdb-doc/Qualifier-milisecond.png)

- Value长度：与秒类型相同。
- Value类型：与秒类型相同。
- 时间戳： 时间戳的值由Qualifier的第5到第26个bit表示，即(qualifier & 0x0FFFFFC0) >>>6。
- 标志位：标志位由Qualifier的前4个bit表示。当该Qualifier表示毫秒级数据时，必须全为1，即(qualifier[0] & 0xF0) == 0xF0。
- 第27到28个bit未使用。



Append模式的列名就是：

net.opentsdb.core.AppendDataPoints#AppendDataPoints()

```
/** The prefix ID of append columns */
public static final byte APPEND_COLUMN_PREFIX = 0x05;

/** The full column qualifier for append columns */
public static final byte[] APPEND_COLUMN_QUALIFIER = new byte[] {
  APPEND_COLUMN_PREFIX, 0x00, 0x00};
  
```

# Scanner的一个很好的例子：

加载指定时间段内的Annotation



net.opentsdb.meta.Annotation

```java
public static Deferred<List<Annotation>> getGlobalAnnotations(final TSDB tsdb, 
      final long start_time, final long end_time)


数据表里面qualifer如果是以\01开头，就是一个Annotation。通过列名来判断
```